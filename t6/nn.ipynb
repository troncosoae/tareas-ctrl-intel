{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-91-8193e86714d8>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_df['neg_faulty'] = 1 - Y_df['faulty']\n"
     ]
    }
   ],
   "source": [
    "path = 'data/values_v2.csv'\n",
    "values_df = pd.read_csv(path)\n",
    "\n",
    "X_keys = ['tau_g', 'tau_gm']\n",
    "Y_keys = ['faulty']\n",
    "X_df = values_df[X_keys]\n",
    "Y_df = values_df[Y_keys]\n",
    "Y_df['neg_faulty'] = 1 - Y_df['faulty']\n",
    "# Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMcovid(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LSTMcovid, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
    "        self.hidden2vals = nn.Linear(hidden_dim, 2)\n",
    "    \n",
    "    def forward(self, sequence):\n",
    "        lstm_out, hidden = self.lstm(sequence)\n",
    "        vals = self.hidden2vals(lstm_out)\n",
    "        tag_scores = F.softmax(vals, dim=2)\n",
    "        return tag_scores\n",
    "    \n",
    "    def suit4model(self, tsr):\n",
    "        return tsr.unsqueeze(1).float()\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 2)\n",
    "    \n",
    "    def forward(self, s):\n",
    "        s = F.relu(self.fc1(s))\n",
    "        s = F.relu(self.fc2(s))\n",
    "        s = F.softmax(s, dim=2)\n",
    "        return s\n",
    "    \n",
    "    def suit4model(self, tsr):\n",
    "        return tsr.unsqueeze(1).float()\n",
    "    \n",
    "\n",
    "def calculate_acc(Y, Y_pred):\n",
    "    Y_preds_args = np.argmax(Y_preds.detach().numpy(), axis=1)\n",
    "    Y_args = np.argmax(Y.detach().numpy(), axis=1)\n",
    "    res = Y_preds_args == Y_args\n",
    "    return np.sum(res)/res.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 20\n",
    "INPUT_DIM = len(X_keys)\n",
    "model = LSTMcovid(INPUT_DIM, HIDDEN_DIM)\n",
    "# model = NN(INPUT_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X_df.values).float()\n",
    "X_norm = X / np.linalg.norm(X, axis=0)\n",
    "Y = torch.tensor(Y_df.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5269, 0.4731]],\n",
      "\n",
      "        [[0.5252, 0.4748]],\n",
      "\n",
      "        [[0.5238, 0.4762]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5198, 0.4802]],\n",
      "\n",
      "        [[0.5198, 0.4802]],\n",
      "\n",
      "        [[0.5198, 0.4802]]]) torch.Size([3551, 1, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_suited = model.suit4model(X_norm)\n",
    "    Y_preds = model(X_suited)\n",
    "    print(Y_preds, Y_preds.shape)\n",
    "    print(Y, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5269, 0.4731],\n",
      "        [0.5252, 0.4748],\n",
      "        [0.5238, 0.4762],\n",
      "        ...,\n",
      "        [0.5198, 0.4802],\n",
      "        [0.5198, 0.4802],\n",
      "        [0.5198, 0.4802]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5167558434243875"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.max(Y_preds.detach().numpy())\n",
    "    \n",
    "# print('acc', calculate_acc(Y, Y_preds.squeeze()))\n",
    "print(Y_preds.squeeze())\n",
    "Y_preds_args = np.argmax(Y_preds.squeeze().detach().numpy(), axis=1)\n",
    "Y_args = np.argmax(Y.detach().numpy(), axis=1)\n",
    "res = Y_preds_args == Y_args\n",
    "np.sum(res)/res.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "tensor([[0.5269, 0.4731],\n",
      "        [0.5252, 0.4748],\n",
      "        [0.5238, 0.4762],\n",
      "        ...,\n",
      "        [0.5198, 0.4802],\n",
      "        [0.5198, 0.4802],\n",
      "        [0.5198, 0.4802]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 1\n",
      "tensor([[0.5269, 0.4731],\n",
      "        [0.5252, 0.4748],\n",
      "        [0.5238, 0.4762],\n",
      "        ...,\n",
      "        [0.5198, 0.4802],\n",
      "        [0.5198, 0.4802],\n",
      "        [0.5198, 0.4802]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 2\n",
      "tensor([[0.5269, 0.4731],\n",
      "        [0.5252, 0.4748],\n",
      "        [0.5238, 0.4762],\n",
      "        ...,\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 3\n",
      "tensor([[0.5269, 0.4731],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5238, 0.4762],\n",
      "        ...,\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 4\n",
      "tensor([[0.5269, 0.4731],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5238, 0.4762],\n",
      "        ...,\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 5\n",
      "tensor([[0.5269, 0.4731],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5238, 0.4762],\n",
      "        ...,\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 6\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5238, 0.4762],\n",
      "        ...,\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 7\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5238, 0.4762],\n",
      "        ...,\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 8\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 9\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 10\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.5197, 0.4803]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 11\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 12\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 13\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 14\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 15\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 16\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 17\n",
      "tensor([[0.5268, 0.4732],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.5237, 0.4763],\n",
      "        ...,\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 18\n",
      "tensor([[0.5267, 0.4733],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.5236, 0.4764],\n",
      "        ...,\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n",
      "epoch: 19\n",
      "tensor([[0.5267, 0.4733],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.5236, 0.4764],\n",
      "        ...,\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804],\n",
      "        [0.5196, 0.4804]], grad_fn=<SqueezeBackward0>) torch.Size([3551, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]) torch.Size([3551, 2])\n",
      "acc 0.5167558434243875\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'epoch: {epoch}')\n",
    "    model.zero_grad()\n",
    "\n",
    "    suited_X = model.suit4model(X_norm)\n",
    "    Y_preds = model(suited_X).squeeze()\n",
    "    print(Y_preds, Y_preds.shape)\n",
    "    print(Y, Y.shape)\n",
    "#     print(Y_preds.type())\n",
    "#     print(Y.type())\n",
    "    \n",
    "    print('acc', calculate_acc(Y, Y_preds))\n",
    "\n",
    "    loss = loss_function(Y_preds, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44959413459020686"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_preds_args = np.argmax(Y_preds.detach().numpy(), axis=1)\n",
    "Y_args = np.argmax(Y.detach().numpy(), axis=1)\n",
    "res = Y_preds_args == Y_args\n",
    "np.sum(res)/res.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
